apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: document-intelligence-app
  namespace: argocd
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  project: cortex-ai
  source:
    repoURL: https://gitlab.cortex.local/ai-services/document-intelligence.git
    targetRevision: main
    path: k8s/overlays/production
  destination:
    server: https://kubernetes.default.svc
    namespace: ai-services
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
      allowEmpty: false
    syncOptions:
      - CreateNamespace=true
      - PrunePropagationPolicy=foreground
      - PruneLast=true
    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m
  revisionHistoryLimit: 5
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: llm-inference-app
  namespace: argocd
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  project: cortex-ai
  source:
    repoURL: https://gitlab.cortex.local/ai-infrastructure/llm-inference.git
    targetRevision: main
    path: k8s/overlays/production
  destination:
    server: https://kubernetes.default.svc
    namespace: ai-inference
  syncPolicy:
    automated:
      prune: false
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ApplyOutOfSyncOnly=true
    retry:
      limit: 3
      backoff:
        duration: 10s
        factor: 2
        maxDuration: 5m
  revisionHistoryLimit: 10
---
# ArgoCD Rollouts for Canary Deployments
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: document-intelligence-rollout
  namespace: ai-services
spec:
  replicas: 3
  strategy:
    canary:
      canaryService: document-intelligence-canary
      stableService: document-intelligence-stable
      trafficRouting:
        istio:
          virtualService:
            name: document-intelligence-vs
            routes:
            - primary
      steps:
      - setWeight: 5
      - pause: 
          duration: 2m
      - analysis:
          templates:
          - templateName: success-rate
          args:
          - name: service-name
            value: document-intelligence-canary
      - setWeight: 25
      - pause:
          duration: 5m
      - analysis:
          templates:
          - templateName: success-rate
          - templateName: response-time
          args:
          - name: service-name
            value: document-intelligence-canary
      - setWeight: 50
      - pause:
          duration: 10m
      - setWeight: 75
      - pause:
          duration: 5m
  selector:
    matchLabels:
      app: document-intelligence-agent
  template:
    metadata:
      labels:
        app: document-intelligence-agent
    spec:
      containers:
      - name: document-agent
        image: harbor.cortex.local/ai-services/document-intelligence:latest
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
---
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: success-rate
  namespace: ai-services
spec:
  args:
  - name: service-name
  metrics:
  - name: success-rate
    interval: 60s
    count: 5
    successCondition: result[0] >= 0.95
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc.cluster.local:9090
        query: |
          sum(rate(http_requests_total{service="{{args.service-name}}",status!~"5.."}[2m])) / 
          sum(rate(http_requests_total{service="{{args.service-name}}"}[2m]))
---
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: response-time
  namespace: ai-services
spec:
  args:
  - name: service-name
  metrics:
  - name: response-time
    interval: 60s
    count: 5
    successCondition: result[0] <= 2000
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc.cluster.local:9090
        query: |
          histogram_quantile(0.95, 
            sum(rate(http_request_duration_seconds_bucket{service="{{args.service-name}}"}[2m])) by (le)
          ) * 1000